{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Tarea_2[1].ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Z0tyIsliieNr"
      },
      "source": [
        "# Tarea 2 - Named Entity Recognition\n",
        "\n",
        "----------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-22T15:21:15.416464Z",
          "start_time": "2020-06-22T15:21:15.411478Z"
        },
        "colab_type": "text",
        "id": "X3QUWWoWaSE3"
      },
      "source": [
        "- **Nombre:** Ignacio Díaz Lara, Felipe Manen Núñez\n",
        "\n",
        "- **Usuario o nombre de equipo en Codalab:** Equipo7\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "f7X2FruyaSFG"
      },
      "source": [
        "\n",
        "-----------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PzQlYlmGaSFH"
      },
      "source": [
        "## Introducción\n",
        "\n",
        "En el presente informe se registra el trabajo realizado para el Sequence Labelling, en particular Named Entity Recognition (NER), sobre un dataset de noticias en español etiquetadas. La tarea por abordar consiste en asignar una etiqueta dada una secuencia de tokens proveniente de una oración. Dicha etiqueta busca reconocer entidades nombradas, es decir, clasificar los tokens que simbolicen personas (clasificadas como PER), organizaciones (ORG), lugares (LOC) y adjetivos, eventos y otras entidades que no entren en las categorías (MISC). Además, como existen entidades representadas en más de un token, se usa como prefijo del tag la notación BIO: Beginning, Inside, Outside. En esta notación, el primer token de una entidad tiene el prefijo B y todos los restantes de la misma entidad tienen el prefijo I. Si no representa ninguna entidad, entonces se usa el prefijo O. \n",
        "\n",
        "Para resolver esta tarea se utilizan Redes Neuronales Recurrentes (RNN). Para esto, el equipo de desarrollo construye diferentes modelos que componen una arquitectura de RNN en Pytorch, y a su vez, varios experimentos que combinan diferentes modelos, épocas, tamaños de batches, embeddings preentrenados, entre otras variables; de tal manera de poder obtener resultados aceptables a la hora de compararlos con los datos etiquetados según las métricas de evaluación dispuestas. Las métricas que se utilizan para evaluar los resultados son Precision, Recall y F1 Score. Todo esto se construye sobre un baseline entregado por el equipo docente, el cual entrega resultados que buscamos mejorar.\n",
        "\n",
        "Como principal conclusión se tiene que las arquitecturas con embeddings preentrenados obtuvieron peores resultados que las arquitecturas sin estos.\n",
        "Sin embargo, se mejoraron los resultados inciales del baseline entregado por el equipo docente en las tres métricas a evaluar y se utilizaron diferentes herramientas para poder optmizar los resultados.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UbA1EmhCaSFI"
      },
      "source": [
        "## Modelos \n",
        "\n",
        "\n",
        "En este informe se presentan cuatro arquitecturas sobre las cuales se experimentan combinando los hiperparámetros que las definien. Las RNN de la arquitectura están programadas en Pytorch, cargan los dataset y crean batches de texto y padding.\n",
        "La primera es una RNN de tipo LSTM que no usa embeddings preentrenados. \n",
        "La segunda es una RNN de tipo GRU que tampoco usa embeddings preentrenados.\n",
        "La tercera es una RNN de tipo LSTM que usa sí usa embeddings preentrenados.\n",
        "Y la cuarta es una RNN de tipo GRU que también usa embeddings preentrenados. \n",
        "Los Embeddings preentrenados que se usaron fueron Glove y FastText en español.\n",
        "Dentro de los hiperparámetros que se varian en este trabajo se encuentran, el tamaño de batch, la cantidad de épocas, la dimensión de los embeddings, la dimensión de las capas ocultas, la cantidad de capas ocultas, el dropout y la bidireccionalidad."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AaVhZ5iaaSFK"
      },
      "source": [
        "## Métricas de evaluación\n",
        "\n",
        "**Recall:**\n",
        "\n",
        "Recall o sensibilidad es la fracción de instancias que han sido recuperadas del total. Se calcula como la proporción de instancia recuperadas realmente positivas sobre el total de instancias positivas y se describe de la siguiente manera:\n",
        "\n",
        "$Recall = \\frac{TruePos }{TruePos +FalseNeg}$\n",
        "\n",
        "Mientras el valor de Recall se acerque más a 1, significa que la cantidad de instancias recuperadas es más cercana al total. Si se acerca a 0, significa que los documentos obtenidos no tienen relevancia.\n",
        "\n",
        "**Precision:**\n",
        "\n",
        "Precision es la fracción de instancias que fueron correctamente identificadas, es decir que fueron recuperadas y son relevantes. Se calcula comparando la proporción entre resultados realmente positivos y negativos en los considerados positivos. y describe así:\n",
        "\n",
        "$Precision = \\frac{TruePos }{TruePos +FalsePos}$\n",
        "\n",
        "Mientras el valor de Precisión sea más cercano a 1, significa que más relevantes son las instancias recuperadas. Por el contrario, mientras más cercano a 0, menos relevantes son.\n",
        "\n",
        "**F1-Score:**\n",
        "\n",
        "Existe un *tradeoff* entre ambas medidas y por eso se puede ponderar ambas en un nuevo valor llamado F1-Score que es la media armónica entre Precision y Recall. Dando igual importancia a ambos la forma del F1-Score es la siguiente:\n",
        "\n",
        "$F_{1}=\\frac{2* Precision* Recall}{Precision+Recall}$\n",
        "\n",
        "Mientras el valor de F1-Score sea más cercano a 1, significa que más perfectos son sus valores de Precision y Recall, ya que son ponderados con la misma relevancia. Mientras que más baje de 1, menos precisos y correctos son los resultados\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-22T15:44:52.175773Z",
          "start_time": "2020-06-22T15:44:52.172782Z"
        },
        "colab_type": "text",
        "id": "uFM-wNt8aSFM"
      },
      "source": [
        "## Experimentos\n",
        "\n",
        "\n",
        "El código que les entregaremos servirá de baseline para luego implementar mejores modelos. \n",
        "En general, el código asociado a la carga de los datos, las funciones de entrenamiento, de evaluación y la predicción de los datos de la competencia no deberían cambiar. \n",
        "Solo deben preocuparse de cambiar la arquitectura del modelo, sus hiperparámetros y reportar, lo cual lo pueden hacer en las subsecciones *modelos*.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LMgKjfYC_Go-"
      },
      "source": [
        "###  Carga de datos y Preprocesamiento\n",
        "\n",
        "Para cargar los datos y preprocesarlos usaremos la librería [`torchtext`](https://github.com/pytorch/text).\n",
        "En particular usaremos su módulo `data`, el cual según su documentación original provee: \n",
        "\n",
        "    - Ability to describe declaratively how to load a custom NLP dataset that's in a \"normal\" format\n",
        "    - Ability to define a preprocessing pipeline\n",
        "    - Batching, padding, and numericalizing (including building a vocabulary object)\n",
        "    - Wrapper for dataset splits (train, validation, test)\n",
        "\n",
        "\n",
        "El proceso será el siguiente: \n",
        "\n",
        "1. Descargar los datos desde github y examinarlos.\n",
        "2. Definir los campos (`fields`) que cargaremos desde los archivos.\n",
        "3. Cargar los datasets.\n",
        "4. Crear el vocabulario.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:24:52.392908Z",
          "start_time": "2020-06-23T22:24:50.641641Z"
        },
        "colab_type": "code",
        "id": "27csY87GaSFO",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "463b5a43-6e17-479b-b1e3-5bfc69177eb6"
      },
      "source": [
        "# Instalar torchtext (en codalab) - Descomentar.\n",
        "#!pip3 install --upgrade torchtext\n",
        "!pip install torchtext==0.6"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchtext==0.6 in /usr/local/lib/python3.6/dist-packages (0.6.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6) (1.15.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6) (0.1.91)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6) (1.18.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6) (1.6.0+cu101)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6) (1.24.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.6) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:24:53.086354Z",
          "start_time": "2020-06-23T22:24:52.394902Z"
        },
        "colab_type": "code",
        "id": "ng7wRGEyawjM",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torchtext import data, datasets\n",
        "\n",
        "\n",
        "# Garantizar reproducibilidad \n",
        "SEED = 1234\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BehSou6rCvwg"
      },
      "source": [
        "#### Obtener datos\n",
        "\n",
        "Descargamos los datos de entrenamiento, validación y prueba en nuestro directorio de trabajo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:49.789218Z",
          "start_time": "2020-06-23T22:24:53.088871Z"
        },
        "colab_type": "code",
        "id": "lbT0g_kC18Jb",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!wget https://github.com/dccuchile/CC6205/releases/download/Data/train_NER_esp.txt -nc # Dataset de Entrenamiento\n",
        "!wget https://github.com/dccuchile/CC6205/releases/download/Data/val_NER_esp.txt -nc    # Dataset de Validación (Para probar y ajustar el modelo)\n",
        "!wget https://github.com/dccuchile/CC6205/releases/download/Data/test_NER_esp.txt -nc  # Dataset de la Competencia. Estos datos solo contienen los tokens. ¡¡SON LOS QUE DEBEN SER PREDICHOS!!"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uMud7YGMBZvg"
      },
      "source": [
        "####  Fields\n",
        "\n",
        "Un `field`:\n",
        "\n",
        "* Define un tipo de datos junto con instrucciones para convertir el texto a Tensor.\n",
        "* Contiene un objeto `Vocab` que contiene el vocabulario (palabras posibles que puede tomar ese campo).\n",
        "* Contiene otros parámetros relacionados con la forma en que se debe numericalizar un tipo de datos, como un método de tokenización y el tipo de Tensor que se debe producir.\n",
        "\n",
        "\n",
        "Analizemos el siguiente cuadro el cual contiene un ejemplo cualquiera de entrenamiento:\n",
        "\n",
        "\n",
        "```\n",
        "El O\n",
        "Abogado B-PER\n",
        "General I-PER\n",
        "del I-PER\n",
        "Estado I-PER\n",
        ", O\n",
        "Daryl B-PER\n",
        "Williams I-PER\n",
        "```\n",
        "\n",
        "Cada linea contiene una palabra y su clase. Para que `torchtext` pueda cargar estos datos, debemos definir como va a leer y separar los componentes de cada una de las lineas.\n",
        "Para esto, definiremos un field para cada uno de esos componentes: Las palabras (`TEXT`) y los NER_TAGS (`clase`).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:49.795126Z",
          "start_time": "2020-06-23T22:25:49.791108Z"
        },
        "colab_type": "code",
        "id": "3DcM_IjgCdzz",
        "colab": {}
      },
      "source": [
        "# Primer Field: TEXT. Representan los tokens de la secuencia\n",
        "TEXT = data.Field(lower=False) \n",
        "\n",
        "# Segundo Field: NER_TAGS. Representan los Tags asociados a cada palabra.\n",
        "NER_TAGS = data.Field(unk_token=None)\n",
        "\n",
        "fields = ((\"text\", TEXT), (\"nertags\", NER_TAGS))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35_9XfUBQdKH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "import gzip\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "import requests\n",
        "\n",
        "GLOVE_FILE = \"glove300d.vec\"\n",
        "# https://github.com/dccuchile/spanish-word-embeddings\n",
        "if not os.path.exists(GLOVE_FILE):\n",
        "    print(f\"Descargando {GLOVE_FILE}\")\n",
        "    url = \"http://dcc.uchile.cl/~jperez/word-embeddings/glove-sbwc.i25.vec.gz\"\n",
        "    response = requests.get(url, stream=True)\n",
        "    try:\n",
        "        with gzip.open(response.raw, \"rb\") as f_in:\n",
        "            with open(GLOVE_FILE, \"wb\") as f_out:\n",
        "                # Funcion util para copiar de un file-like object a otro\n",
        "                shutil.copyfileobj(f_in, f_out)\n",
        "    except Exception as e:\n",
        "        os.remove(GLOVE_FILE)\n",
        "        raise e"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uL5CcIEBL2XT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0b35888c-019e-4a09-a004-779339b1bb36"
      },
      "source": [
        "import csv\n",
        "import gzip\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "import requests\n",
        "\n",
        "FASTTEXT_FILE = \"fastText300d.vec\"\n",
        "# https://github.com/dccuchile/spanish-word-embeddings\n",
        "if not os.path.exists(FASTTEXT_FILE):\n",
        "    print(f\"Descargando {FASTTEXT_FILE}\")\n",
        "    url = \"http://dcc.uchile.cl/~jperez/word-embeddings/fasttext-sbwc.vec.gz\"\n",
        "    response = requests.get(url, stream=True)\n",
        "    try:\n",
        "        with gzip.open(response.raw, \"rb\") as f_in:\n",
        "            with open(FASTTEXT_FILE, \"wb\") as f_out:\n",
        "                # Funcion util para copiar de un file-like object a otro\n",
        "                shutil.copyfileobj(f_in, f_out)\n",
        "    except Exception as e:\n",
        "        os.remove(FASTTEXT_FILE)\n",
        "        raise e"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Descargando fastText300d.vec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxByVzp8SYaJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchtext import vocab\n",
        "\n",
        "# Para cargar los vectores de embeddings (que son esencialmente un vocabulario\n",
        "# donde cada palabra tiene asociado un vector) pueden usar la clase vocab.Vectors\n",
        "es_embeddings = vocab.Vectors(FASTTEXT_FILE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xCKTJOdgC5eC"
      },
      "source": [
        "####  SequenceTaggingDataset\n",
        "\n",
        "`SequenceTaggingDataset` es una clase de torchtext diseñada para contener datasets de sequence labelling. \n",
        "Los ejemplos que se guarden en una instancia de estos serán arreglos de palabras pareados con sus respectivos tags.\n",
        "Por ejemplo, para Part-of-speech tagging:\n",
        "\n",
        "[I, love, PyTorch, .] estará pareado con [PRON, VERB, PROPN, PUNCT]\n",
        "\n",
        "\n",
        "La idea es que usando los fields que definimos antes, le indiquemos a la clase cómo cargar los datasets de prueba, validación y test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:50.294370Z",
          "start_time": "2020-06-23T22:25:49.797092Z"
        },
        "colab_type": "code",
        "id": "HsHdGml62J21",
        "colab": {}
      },
      "source": [
        "train_data, valid_data, test_data = datasets.SequenceTaggingDataset.splits(\n",
        "    path=\"./\",\n",
        "    train=\"train_NER_esp.txt\",\n",
        "    validation=\"val_NER_esp.txt\",\n",
        "    test=\"test_NER_esp.txt\",\n",
        "    fields=fields,\n",
        "    encoding=\"iso-8859-1\",\n",
        "    separator=\" \"\n",
        ")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:50.301354Z",
          "start_time": "2020-06-23T22:25:50.296368Z"
        },
        "colab_type": "code",
        "id": "Hu7q3HCliia5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "ba2ac26d-09bb-439a-cf7e-0d6983e47648"
      },
      "source": [
        "print(f\"Numero de ejemplos de entrenamiento: {len(train_data)}\")\n",
        "print(f\"Número de ejemplos de validación: {len(valid_data)}\")\n",
        "print(f\"Número de ejemplos de test (competencia): {len(test_data)}\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Numero de ejemplos de entrenamiento: 8323\n",
            "Número de ejemplos de validación: 1915\n",
            "Número de ejemplos de test (competencia): 1517\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fDRnhXAdFGL-"
      },
      "source": [
        "Visualizemos un ejemplo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:50.317313Z",
          "start_time": "2020-06-23T22:25:50.303361Z"
        },
        "colab_type": "code",
        "id": "T023Ld4RaSF4",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "outputId": "47d955be-cf2d-420a-ae1d-01eff57cb18a"
      },
      "source": [
        "import random\n",
        "random_item_idx = random.randint(0, len(train_data))\n",
        "random_example = train_data.examples[random_item_idx]\n",
        "list(zip(random_example.text, random_example.nertags))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('El', 'O'),\n",
              " ('presidente', 'O'),\n",
              " ('de', 'O'),\n",
              " ('la', 'O'),\n",
              " ('FGF', 'B-ORG'),\n",
              " ('dijo', 'O'),\n",
              " ('que', 'O'),\n",
              " ('\"', 'O'),\n",
              " ('Camacho', 'B-PER'),\n",
              " ('pretende', 'O'),\n",
              " ('recuperar', 'O'),\n",
              " ('a', 'O'),\n",
              " ('los', 'O'),\n",
              " ('jugadores', 'O'),\n",
              " ('y', 'O'),\n",
              " ('que', 'O'),\n",
              " ('descansen', 'O'),\n",
              " (',', 'O'),\n",
              " ('ese', 'O'),\n",
              " ('es', 'O'),\n",
              " ('el', 'O'),\n",
              " ('objetivo', 'O'),\n",
              " ('de', 'O'),\n",
              " ('la', 'O'),\n",
              " ('concentración', 'O'),\n",
              " ('de', 'O'),\n",
              " ('La', 'B-LOC'),\n",
              " ('Toja', 'I-LOC'),\n",
              " (',', 'O'),\n",
              " ('aunque', 'O'),\n",
              " ('hará', 'O'),\n",
              " ('algunos', 'O'),\n",
              " ('entrenamientos', 'O'),\n",
              " ('\"', 'O'),\n",
              " ('.', 'O')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2l05KYy5FSUy"
      },
      "source": [
        "#### Construir los vocabularios para el texto y las etiquetas\n",
        "\n",
        "Los vocabularios son los obbjetos que contienen todos los tokens (de entrenamiento) posibles para ambos fields.\n",
        "El siguiente paso consiste en construirlos. Para esto, hacemos uso del método `Field.build_vocab` sobre cada uno de nuestros `fields`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:50.445968Z",
          "start_time": "2020-06-23T22:25:50.320305Z"
        },
        "colab_type": "code",
        "id": "PBhp7WICiibL",
        "colab": {}
      },
      "source": [
        "TEXT.build_vocab(train_data)\n",
        "NER_TAGS.build_vocab(train_data)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WytWYhnLTOv_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#para embeddings\n",
        "from operator import attrgetter\n",
        "\n",
        "TEXT.vocab.set_vectors(*attrgetter(\"stoi\", \"vectors\", \"dim\")(es_embeddings))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:50.453960Z",
          "start_time": "2020-06-23T22:25:50.448987Z"
        },
        "colab_type": "code",
        "id": "M4OgUKM_iibO",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7abbf892-4de8-4df6-c4e4-a26458dbffd9"
      },
      "source": [
        "print(f\"Tokens únicos en TEXT: {len(TEXT.vocab)}\")\n",
        "print(f\"Tokens únicos en NER_TAGS: {len(NER_TAGS.vocab)}\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokens únicos en TEXT: 26101\n",
            "Tokens únicos en NER_TAGS: 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:50.460965Z",
          "start_time": "2020-06-23T22:25:50.455942Z"
        },
        "colab_type": "code",
        "id": "d4FeyL9nFnId",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "e777d982-7923-4a6f-8a0c-2817dfa240e5"
      },
      "source": [
        "#Veamos las posibles etiquetas que hemos cargado:\n",
        "NER_TAGS.vocab.itos"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<pad>',\n",
              " 'O',\n",
              " 'B-ORG',\n",
              " 'I-ORG',\n",
              " 'B-LOC',\n",
              " 'B-PER',\n",
              " 'I-PER',\n",
              " 'I-MISC',\n",
              " 'B-MISC',\n",
              " 'I-LOC']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HYQDoUqSHFKj"
      },
      "source": [
        "Observen que ademas de los tags NER, tenemos \\<pad\\>, el cual es generado por el dataloader para cumplir con el padding de cada oración.\n",
        "\n",
        "Veamos ahora los tokens mas frecuentes y especiales:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:50.473893Z",
          "start_time": "2020-06-23T22:25:50.462923Z"
        },
        "colab_type": "code",
        "id": "m5eSLm4diibR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "83564031-f39a-4546-b882-8c5b6a15d4aa"
      },
      "source": [
        "# Tokens mas frecuentes\n",
        "TEXT.vocab.freqs.most_common(10)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('de', 17657),\n",
              " (',', 14716),\n",
              " ('la', 9571),\n",
              " ('que', 7516),\n",
              " ('.', 7263),\n",
              " ('el', 6905),\n",
              " ('en', 6484),\n",
              " ('\"', 5691),\n",
              " ('y', 5336),\n",
              " ('a', 4304)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:50.479897Z",
          "start_time": "2020-06-23T22:25:50.475889Z"
        },
        "id": "nUaErFetTFOe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Seteamos algunas variables que nos serán de utilidad mas adelante...\n",
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "PAD_TAG_IDX = NER_TAGS.vocab.stoi[NER_TAGS.pad_token]\n",
        "O_TAG_IDX = NER_TAGS.vocab.stoi['O']"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qrYvF3X0sjWL"
      },
      "source": [
        "#### Frecuencia de los Tags\n",
        "\n",
        "Visualizemos rápidamente las cantidades y frecuencias de cada tag:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:50.490885Z",
          "start_time": "2020-06-23T22:25:50.481873Z"
        },
        "colab_type": "code",
        "id": "tuXOsbJUiibh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "4d0eda25-8ade-4104-fca9-dd5b5f1218e4"
      },
      "source": [
        "def tag_percentage(tag_counts):\n",
        "    \n",
        "    total_count = sum([count for tag, count in tag_counts])\n",
        "    tag_counts_percentages = [(tag, count, count/total_count) for tag, count in tag_counts]\n",
        "  \n",
        "    return tag_counts_percentages\n",
        "\n",
        "print(\"Tag Ocurrencia Porcentaje\\n\")\n",
        "\n",
        "for tag, count, percent in tag_percentage(NER_TAGS.vocab.freqs.most_common()):\n",
        "    print(f\"{tag}\\t{count}\\t{percent*100:4.1f}%\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tag Ocurrencia Porcentaje\n",
            "\n",
            "O\t231920\t87.6%\n",
            "B-ORG\t7390\t 2.8%\n",
            "I-ORG\t4992\t 1.9%\n",
            "B-LOC\t4913\t 1.9%\n",
            "B-PER\t4321\t 1.6%\n",
            "I-PER\t3903\t 1.5%\n",
            "I-MISC\t3212\t 1.2%\n",
            "B-MISC\t2173\t 0.8%\n",
            "I-LOC\t1891\t 0.7%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-22T21:44:17.730460Z",
          "start_time": "2020-06-22T21:44:17.724482Z"
        },
        "colab_type": "text",
        "id": "y4wPiydnaSGs"
      },
      "source": [
        "#### Configuramos pytorch y dividimos los datos.\n",
        "\n",
        "Importante: si tienes problemas con la ram de la gpu, disminuye el tamaño de los batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:51.101455Z",
          "start_time": "2020-06-23T22:25:50.492843Z"
        },
        "colab_type": "code",
        "id": "uB7cwLWpaSGs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5f22f317-c447-46a4-e5e6-a99e4660a1aa"
      },
      "source": [
        "BATCH_SIZE = 64  # disminuir si hay problemas de ram.\n",
        "\n",
        "# Usar cuda si es que está disponible.\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using', device)\n",
        "\n",
        "# Dividir datos entre entrenamiento y test\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    device=device,\n",
        "    sort=False,\n",
        ")"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "B21E1eAFId16"
      },
      "source": [
        "#### Métricas de evaluación\n",
        "\n",
        "Además, definiremos las métricas que serán usadas tanto para la competencia como para evaluar el modelo: `precision`, `recall` y `f1`.\n",
        "**Importante**: Noten que la evaluación solo se hace para las Named Entities (sin contar 'O')."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:51.654826Z",
          "start_time": "2020-06-23T22:25:51.103450Z"
        },
        "colab_type": "code",
        "id": "9mUOOLEWiicU",
        "colab": {}
      },
      "source": [
        "# Definimos las métricas\n",
        "\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "import warnings\n",
        "import sklearn.exceptions\n",
        "warnings.filterwarnings(\"ignore\",\n",
        "                        category=sklearn.exceptions.UndefinedMetricWarning)\n",
        "\n",
        "\n",
        "def calculate_metrics(preds, y_true, pad_idx=PAD_TAG_IDX, o_idx=O_TAG_IDX):\n",
        "    \"\"\"\n",
        "    Calcula precision, recall y f1 de cada batch.\n",
        "    \"\"\"\n",
        "\n",
        "    # Obtener el indice de la clase con probabilidad mayor. (clases)\n",
        "    y_pred = preds.argmax(dim=1, keepdim=True)\n",
        "    # Obtenemos los indices distintos de 0.\n",
        "\n",
        "    # filtramos <pad> y O para calcular los scores.\n",
        "    mask = [(y_true != o_idx) & (y_true != pad_idx)]\n",
        "    y_pred = y_pred[mask]\n",
        "    y_true = y_true[mask]\n",
        "\n",
        "    # traemos a la cpu\n",
        "    y_pred = y_pred.view(-1).to('cpu')\n",
        "    y_true = y_true.to('cpu')\n",
        "    \n",
        "    # calcular scores\n",
        "    f1 = f1_score(y_true, y_pred, average='macro')\n",
        "    precision = precision_score(y_true, y_pred, average='macro')\n",
        "    recall = recall_score(y_true, y_pred, average='macro')\n",
        "\n",
        "    return precision, recall, f1"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Hod516H1aSG2"
      },
      "source": [
        "-------------------\n",
        "\n",
        "### Modelo Baseline\n",
        "\n",
        "Teniendo ya cargado los datos, toca definir nuestro modelo. Este baseline tendrá una capa de embedding, unas cuantas LSTM y una capa de salida y usará dropout en el entrenamiento.\n",
        "\n",
        "Este constará de los siguientes pasos: \n",
        "\n",
        "1. Definir la clase que contendrá la red.\n",
        "2. Definir los hiperparámetros e inicializar la red. \n",
        "3. Definir la época de entrenamiento\n",
        "3. Definir la función de loss.\n",
        "\n",
        "\n",
        "\n",
        "Recomendamos que para experimentar, encapsules los modelos en una sola variable y luego la fijes en model para entrenarla"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:51.666751Z",
          "start_time": "2020-06-23T22:25:51.656778Z"
        },
        "colab_type": "code",
        "id": "rMPL08XqaSG3",
        "colab": {}
      },
      "source": [
        "#baseline\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "# Definir la red\n",
        "class NER_RNN(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim, \n",
        "                 embedding_dim, \n",
        "                 hidden_dim, \n",
        "                 output_dim,\n",
        "                 n_layers, \n",
        "                 bidirectional, \n",
        "                 dropout, \n",
        "                 pad_idx):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # Capa de embedding\n",
        "        self.embedding = nn.Embedding(input_dim,\n",
        "                                      embedding_dim,\n",
        "                                      padding_idx=pad_idx)\n",
        "\n",
        "        # Capa LSTM\n",
        "        self.lstm = nn.LSTM(embedding_dim,\n",
        "                           hidden_dim,\n",
        "                           num_layers=n_layers,\n",
        "                           bidirectional=bidirectional, \n",
        "                           dropout = dropout if n_layers > 1 else 0)\n",
        "\n",
        "        # Capa de salida\n",
        "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim,\n",
        "                            output_dim)\n",
        "\n",
        "        # Dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, text):\n",
        "\n",
        "        #text = [sent len, batch size]\n",
        "\n",
        "        # Convertir lo enviado a embedding\n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "        #outputs, hn = self.gru(embedded)\n",
        "        outputs, (hidden, cell) = self.lstm(embedded)\n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "\n",
        "        # Pasar los embeddings por la rnn (LSTM)\n",
        "\n",
        "        #output = [sent len, batch size, hid dim * n directions]\n",
        "        #hidden/cell = [n layers * n directions, batch size, hid dim]\n",
        "\n",
        "        # Predecir usando la capa de salida.\n",
        "        predictions = self.fc(self.dropout(outputs))\n",
        "        #predictions = [sent len, batch size, output dim]\n",
        "\n",
        "        return predictions"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xloOY_ghjc8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#modelo con embedding preentrenados y gru\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "# Definir la red\n",
        "class NER_RNN_pre_embeddings_LSTM(nn.Module):\n",
        "    def __init__(self,\n",
        "                 embedding_dim,  \n",
        "                 embedding_weights,\n",
        "                 hidden_dim, \n",
        "                 output_dim,\n",
        "                 n_layers, \n",
        "                 bidirectional, \n",
        "                 dropout, \n",
        "                 pad_idx):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # Capa de embedding\n",
        "        #self.embedding = nn.Embedding(input_dim,\n",
        "        #                              embedding_dim,\n",
        "        #                              padding_idx=pad_idx)\n",
        "        self.embedding = nn.Embedding.from_pretrained(\n",
        "            embedding_weights.clone(), freeze=True\n",
        "        )\n",
        "        #self.fc = nn.Linear(embedding_weights.shape[1], num_class)\n",
        "        # Capa LSTM\n",
        "        self.lstm = nn.LSTM(embedding_dim,\n",
        "                           hidden_dim,\n",
        "                           num_layers=n_layers,\n",
        "                           bidirectional=bidirectional, \n",
        "                           dropout = dropout if n_layers > 1 else 0)\n",
        "\n",
        "        # Capa de salida\n",
        "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim,\n",
        "                            output_dim)\n",
        "\n",
        "        # Dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, text):\n",
        "        embedded = self.embedding(text)\n",
        "        #return self.fc(embedded)\n",
        "        #text = [sent len, batch size]\n",
        "\n",
        "        # Convertir lo enviado a embedding\n",
        "        #embedded = self.dropout(self.embedding(text))\n",
        "        #outputs, hn = self.lstm(embedded)\n",
        "        outputs, (hidden, cell) = self.lstm(embedded)\n",
        "        #outputs, (hidden, cell) = self.lstm(embedded)\n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "\n",
        "        # Pasar los embeddings por la rnn (LSTM)\n",
        "\n",
        "        #output = [sent len, batch size, hid dim * n directions]\n",
        "        #hidden/cell = [n layers * n directions, batch size, hid dim]\n",
        "\n",
        "        # Predecir usando la capa de salida.\n",
        "        predictions = self.fc(self.dropout(outputs))\n",
        "        #predictions = [sent len, batch size, output dim]\n",
        "\n",
        "        return predictions"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMSuK0ipuYhq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#RNN con GRU sin embedding preentrenados\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "# Definir la red\n",
        "class NER_RNN_GRU(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim, \n",
        "                 embedding_dim, \n",
        "                 hidden_dim, \n",
        "                 output_dim,\n",
        "                 n_layers, \n",
        "                 bidirectional, \n",
        "                 dropout, \n",
        "                 pad_idx):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # Capa de embedding\n",
        "        self.embedding = nn.Embedding(input_dim,\n",
        "                                      embedding_dim,\n",
        "                                      padding_idx=pad_idx)\n",
        "\n",
        "        # Capa LSTM\n",
        "        self.gru = nn.GRU(embedding_dim,\n",
        "                           hidden_dim,\n",
        "                           num_layers=n_layers,\n",
        "                           bidirectional=bidirectional, \n",
        "                           dropout = dropout if n_layers > 1 else 0)\n",
        "\n",
        "        # Capa de salida\n",
        "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim,\n",
        "                            output_dim)\n",
        "\n",
        "        # Dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, text):\n",
        "\n",
        "        #text = [sent len, batch size]\n",
        "\n",
        "        # Convertir lo enviado a embedding\n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "        outputs, hn = self.gru(embedded)\n",
        "        #outputs, (hidden, cell) = self.lstm(embedded)\n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "\n",
        "        # Pasar los embeddings por la rnn (LSTM)\n",
        "\n",
        "        #output = [sent len, batch size, hid dim * n directions]\n",
        "        #hidden/cell = [n layers * n directions, batch size, hid dim]\n",
        "\n",
        "        # Predecir usando la capa de salida.\n",
        "        predictions = self.fc(self.dropout(outputs))\n",
        "        #predictions = [sent len, batch size, output dim]\n",
        "\n",
        "        return predictions"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02dM_uqpTuCa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#modelo con embedding preentrenados y gru\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "# Definir la red\n",
        "class NER_RNN_pre_embeddings(nn.Module):\n",
        "    def __init__(self,\n",
        "                 embedding_dim,  \n",
        "                 embedding_weights,\n",
        "                 hidden_dim, \n",
        "                 output_dim,\n",
        "                 n_layers, \n",
        "                 bidirectional, \n",
        "                 dropout, \n",
        "                 pad_idx):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # Capa de embedding\n",
        "        #self.embedding = nn.Embedding(input_dim,\n",
        "        #                              embedding_dim,\n",
        "        #                              padding_idx=pad_idx)\n",
        "        self.embedding = nn.Embedding.from_pretrained(\n",
        "            embedding_weights.clone(), freeze=True\n",
        "        )\n",
        "        #self.fc = nn.Linear(embedding_weights.shape[1], num_class)\n",
        "        # Capa LSTM\n",
        "        self.gru = nn.GRU(embedding_dim,\n",
        "                           hidden_dim,\n",
        "                           num_layers=n_layers,\n",
        "                           bidirectional=bidirectional, \n",
        "                           dropout = dropout if n_layers > 1 else 0)\n",
        "\n",
        "        # Capa de salida\n",
        "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim,\n",
        "                            output_dim)\n",
        "\n",
        "        # Dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, text):\n",
        "        embedded = self.embedding(text)\n",
        "        #return self.fc(embedded)\n",
        "        #text = [sent len, batch size]\n",
        "\n",
        "        # Convertir lo enviado a embedding\n",
        "        #embedded = self.dropout(self.embedding(text))\n",
        "        outputs, hn = self.gru(embedded)\n",
        "        #outputs, (hidden, cell) = self.lstm(embedded)\n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "\n",
        "        # Pasar los embeddings por la rnn (LSTM)\n",
        "\n",
        "        #output = [sent len, batch size, hid dim * n directions]\n",
        "        #hidden/cell = [n layers * n directions, batch size, hid dim]\n",
        "\n",
        "        # Predecir usando la capa de salida.\n",
        "        predictions = self.fc(self.dropout(outputs))\n",
        "        #predictions = [sent len, batch size, output dim]\n",
        "\n",
        "        return predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-22T21:43:02.333880Z",
          "start_time": "2020-06-22T21:43:02.329861Z"
        },
        "colab_type": "text",
        "id": "cCl3530VaSG7"
      },
      "source": [
        "#### Hiperparámetros de la red\n",
        "\n",
        "Definimos los hiperparámetros. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUwVSXRUISYb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Hiperparámetros Baseline\n",
        "# tamaño del vocabulario. recuerden que la entrada son vectores bag of word(one-hot).\n",
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100  # dimensión de los embeddings.\n",
        "HIDDEN_DIM = 256  # dimensión de la capas LSTM\n",
        "OUTPUT_DIM = len(NER_TAGS.vocab)  # número de clases\n",
        "\n",
        "N_LAYERS = 5  # número de capas.\n",
        "DROPOUT = 0.25\n",
        "BIDIRECTIONAL = True\n",
        "\n",
        "# Creamos nuestro modelo.\n",
        "baseline_model = NER_RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM,\n",
        "                         N_LAYERS, BIDIRECTIONAL, DROPOUT, PAD_IDX)\n",
        "\n",
        "baseline_model_name = 'baseline'  # nombre que tendrá el modelo guardado.."
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:51.705684Z",
          "start_time": "2020-06-23T22:25:51.668746Z"
        },
        "colab_type": "code",
        "id": "EHdi3QdOaSG8",
        "colab": {}
      },
      "source": [
        "# Hiperparámetros NER_RNN_pre_embeddings\n",
        "INPUT_DIM_1 = len(TEXT.vocab)\n",
        "EMBEDDING_DIM_1 = 300  # dimensión de los embeddings.\n",
        "HIDDEN_DIM_1 = 128  # dimensión de la capas LSTM\n",
        "OUTPUT_DIM_1 = len(NER_TAGS.vocab)  # número de clases\n",
        "EMBEDDING_WEIGHTS_1 = TEXT.vocab.vectors\n",
        "\n",
        "N_LAYERS_1 = 5  # número de capas.\n",
        "DROPOUT_1 = 0.1\n",
        "BIDIRECTIONAL_1 = True\n",
        "\n",
        "# Creamos nuestro modelo.\n",
        "model_embeddings_1 = NER_RNN_pre_embeddings(EMBEDDING_DIM_1, EMBEDDING_WEIGHTS_1, HIDDEN_DIM_1, OUTPUT_DIM_1,\n",
        "                         N_LAYERS_1, BIDIRECTIONAL_1, DROPOUT_1, PAD_IDX)\n",
        "\n",
        "model_embeddings_name_1 = 'modelo NER_RNN_pre_embeddings'  # nombre que tendrá el modelo guardado..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pQOMC_fvfc4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hiperparámetros NER_RNN_GRU\n",
        "INPUT_DIM_2 = len(TEXT.vocab)\n",
        "EMBEDDING_DIM_2 = 300  # dimensión de los embeddings.\n",
        "HIDDEN_DIM_2 = 128  # dimensión de la capas LSTM\n",
        "OUTPUT_DIM_2 = len(NER_TAGS.vocab)  # número de clases\n",
        "\n",
        "\n",
        "N_LAYERS_2 = 3  # número de capas.\n",
        "DROPOUT_2 = 0.25\n",
        "BIDIRECTIONAL_2 = True\n",
        "\n",
        "# Creamos nuestro modelo.\n",
        "model_embeddings_2 = NER_RNN_GRU(INPUT_DIM_2, EMBEDDING_DIM_2, HIDDEN_DIM_2, OUTPUT_DIM_2,\n",
        "                         N_LAYERS_2, BIDIRECTIONAL_2, DROPOUT_2, PAD_IDX)\n",
        "\n",
        "model_embeddings_name_2 = 'modelo NER_RNN_GRU sin embedding'  # nombre que tendrá el modelo guardado..."
      ],
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2xUvNSqkDFS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hiperparámetros NER_RNN_pre_embeddings_LSTM\n",
        "INPUT_DIM_3 = len(TEXT.vocab)\n",
        "EMBEDDING_DIM_3 = 300  # dimensión de los embeddings.\n",
        "HIDDEN_DIM_3 = 128  # dimensión de la capas LSTM\n",
        "OUTPUT_DIM_3 = len(NER_TAGS.vocab)  # número de clases\n",
        "EMBEDDING_WEIGHTS_3 = TEXT.vocab.vectors\n",
        "\n",
        "N_LAYERS_3 = 5  # número de capas.\n",
        "DROPOUT_3 = 0.1\n",
        "BIDIRECTIONAL_3 = False\n",
        "\n",
        "# Creamos nuestro modelo.\n",
        "model_embeddings_3 = NER_RNN_pre_embeddings_LSTM(EMBEDDING_DIM_3, EMBEDDING_WEIGHTS_3, HIDDEN_DIM_3, OUTPUT_DIM_3,\n",
        "                         N_LAYERS_3, BIDIRECTIONAL_3, DROPOUT_3, PAD_IDX)\n",
        "\n",
        "model_embeddings_name_3 = 'modelo NER_RNN_pre_embeddings_LSTM'  # nombre que tendrá el modelo guardado..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:51.710633Z",
          "start_time": "2020-06-23T22:25:51.706649Z"
        },
        "colab_type": "code",
        "id": "jlF1DhJeaSHA",
        "colab": {}
      },
      "source": [
        "baseline_n_epochs = 10"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "s3u4imJGaSHE"
      },
      "source": [
        "#### Definimos la función de loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:51.715637Z",
          "start_time": "2020-06-23T22:25:51.712628Z"
        },
        "colab_type": "code",
        "id": "6G_4k99_aSHG",
        "colab": {}
      },
      "source": [
        "# Loss: Cross Entropy\n",
        "TAG_PAD_IDX = NER_TAGS.vocab.stoi[NER_TAGS.pad_token]\n",
        "baseline_criterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)\n"
      ],
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lRYOEDiQaSHK"
      },
      "source": [
        "--------------------\n",
        "### Modelo 1\n",
        "\n",
        "En estas secciones pueden implementar nuevas redes al modificar los hiperparámetros, la cantidad de épocas de entrenamiento, el tamaño de los batches, loss, optimizador, etc... como también definir nuevas arquitecturas de red (mediante la creación de clases nuevas)\n",
        "\n",
        "\n",
        "Al final de estas, hay 4 variables, las cuales deben setear con los modelos, épocas de entrenamiento, loss y optimizador que deseen probar.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:51.722604Z",
          "start_time": "2020-06-23T22:25:51.717615Z"
        },
        "colab_type": "code",
        "id": "c81f8ki5aSHL",
        "colab": {}
      },
      "source": [
        "model_1 = model_embeddings_1\n",
        "model_name_1 = model_embeddings_name_1\n",
        "n_epochs_1 = 20\n",
        "loss_1 = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rV9oLkN1aSHO"
      },
      "source": [
        "---------------\n",
        "\n",
        "### Modelo 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:51.728587Z",
          "start_time": "2020-06-23T22:25:51.724596Z"
        },
        "colab_type": "code",
        "id": "KWPzETaNaSHP",
        "colab": {}
      },
      "source": [
        "model_2 = model_embeddings_2\n",
        "model_name_2 = model_embeddings_name_2\n",
        "n_epochs_2 = 10\n",
        "loss_2 = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-22T16:07:45.755561Z",
          "start_time": "2020-06-22T16:07:45.751571Z"
        },
        "colab_type": "text",
        "id": "Zpy3p7YaaSHT"
      },
      "source": [
        "---------------\n",
        "\n",
        "\n",
        "### Modelo 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:51.733572Z",
          "start_time": "2020-06-23T22:25:51.730580Z"
        },
        "colab_type": "code",
        "id": "_w0CFjA8aSHU",
        "colab": {}
      },
      "source": [
        "model_3 = model_embeddings_3\n",
        "model_name_3 = model_embeddings_name_3\n",
        "n_epochs_3 = 20\n",
        "loss_3 = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzBxGzpzlyed",
        "colab_type": "text"
      },
      "source": [
        "Modelo 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaR5rw92l0Nw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_4 = baseline_model\n",
        "model_name_4 = baseline_model_name\n",
        "n_epochs_4 = 15\n",
        "loss_4 = baseline_criterion"
      ],
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aPGdirx7aSHZ"
      },
      "source": [
        "------\n",
        "### Entrenamos y evaluamos\n",
        "\n",
        "\n",
        "**Importante** : Fijen el modelo, el número de épocas de entrenamiento, la loss y el optimizador que usarán para entrenar y evaluar en las siguientes variables!!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:51.748571Z",
          "start_time": "2020-06-23T22:25:51.739556Z"
        },
        "colab_type": "code",
        "id": "r8YlGnjxaSHZ",
        "colab": {}
      },
      "source": [
        "model = model_2\n",
        "model_name = model_name_2\n",
        "criterion = loss_2\n",
        "n_epochs = n_epochs_2"
      ],
      "execution_count": 231,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Pu_lXic2aSHd"
      },
      "source": [
        "\n",
        "\n",
        "#### Inicializamos la red\n",
        "\n",
        "iniciamos los pesos de la red de forma aleatoria (Usando una distribución normal).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:51.805380Z",
          "start_time": "2020-06-23T22:25:51.751524Z"
        },
        "colab_type": "code",
        "id": "Q-G_NWFcaSHe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "6af19cf9-0fe4-4fce-a49d-d15a018d5bbc"
      },
      "source": [
        "def init_weights(m):\n",
        "    # Inicializamos los pesos como aleatorios\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.normal_(param.data, mean=0, std=0.1) \n",
        "        \n",
        "    # Seteamos como 0 los embeddings de UNK y PAD.\n",
        "    model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM_2)\n",
        "    model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM_2)\n",
        "        \n",
        "model.apply(init_weights)"
      ],
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NER_RNN_GRU(\n",
              "  (embedding): Embedding(26101, 300, padding_idx=1)\n",
              "  (gru): GRU(300, 256, num_layers=2, dropout=0.25, bidirectional=True)\n",
              "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
              "  (dropout): Dropout(p=0.25, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 232
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:51.812389Z",
          "start_time": "2020-06-23T22:25:51.806377Z"
        },
        "colab_type": "code",
        "id": "mjWDX2CJaSHh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f3d893c3-786c-46db-bc3c-f12a0c532498"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'El modelo actual tiene {count_parameters(model):,} parámetros entrenables.')"
      ],
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "El modelo actual tiene 9,875,238 parámetros entrenables.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UVqBqerlaSHk"
      },
      "source": [
        "Por último, definimos los embeddings que representan a \\<unk\\> y \\<pad\\>  como [0, 0, ..., 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rVZvHtwpaSHq"
      },
      "source": [
        "#### Definimos el optimizador"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:51.819370Z",
          "start_time": "2020-06-23T22:25:51.814357Z"
        },
        "colab_type": "code",
        "id": "AH6o8_cTaSHq",
        "colab": {}
      },
      "source": [
        "# Optimizador\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": 234,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Fz39wa78wGYR"
      },
      "source": [
        "#### Enviamos el modelo a cuda\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:54.503226Z",
          "start_time": "2020-06-23T22:25:51.821338Z"
        },
        "colab_type": "code",
        "id": "dqr0AJ6_iicR",
        "colab": {}
      },
      "source": [
        "# Enviamos el modelo y la loss a cuda (en el caso en que esté disponible)\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 235,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8xlq48WjiW6U"
      },
      "source": [
        "#### Definimos el entrenamiento de la red\n",
        "\n",
        "Algunos conceptos previos: \n",
        "\n",
        "- `epoch` : una pasada de entrenamiento completa de una dataset.\n",
        "- `batch`: una fracción de la época. Se utilizan para entrenar mas rápidamente la red. (mas eficiente pasar n datos que uno en cada ejecución del backpropagation)\n",
        "\n",
        "Esta función está encargada de entrenar la red en una época. Para esto, por cada batch de la época actual, predice los tags del texto, calcula su loss y luego hace backpropagation para actualizar los pesos de la red.\"\n",
        "\n",
        "Observación: En algunos comentarios aparecerá el tamaño de los tensores entre corchetes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:54.515194Z",
          "start_time": "2020-06-23T22:25:54.505221Z"
        },
        "colab_type": "code",
        "id": "DV6YLt0oiicW",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_precision = 0\n",
        "    epoch_recall = 0\n",
        "    epoch_f1 = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    # Por cada batch del iterador de la época:\n",
        "    for batch in iterator:\n",
        "\n",
        "        # Extraemos el texto y los tags del batch que estamos procesado\n",
        "        text = batch.text\n",
        "        tags = batch.nertags\n",
        "\n",
        "        # Reiniciamos los gradientes calculados en la iteración anterior\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        #text = [sent len, batch size]\n",
        "\n",
        "        # Predecimos los tags del texto del batch.\n",
        "        predictions = model(text)\n",
        "\n",
        "        #predictions = [sent len, batch size, output dim]\n",
        "        #tags = [sent len, batch size]\n",
        "\n",
        "        # Reordenamos los datos para calcular la loss\n",
        "        predictions = predictions.view(-1, predictions.shape[-1])\n",
        "        tags = tags.view(-1)\n",
        "\n",
        "        #predictions = [sent len * batch size, output dim]\n",
        "        #tags = [sent len * batch size]\n",
        "\n",
        "        # Calculamos el Cross Entropy de las predicciones con respecto a las etiquetas reales\n",
        "        loss = criterion(predictions, tags)\n",
        "        \n",
        "        # Calculamos el accuracy\n",
        "        precision, recall, f1 = calculate_metrics(predictions, tags)\n",
        "\n",
        "        # Calculamos los gradientes\n",
        "        loss.backward()\n",
        "\n",
        "        # Actualizamos los parámetros de la red\n",
        "        optimizer.step()\n",
        "\n",
        "        # Actualizamos el loss y las métricas\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_precision += precision\n",
        "        epoch_recall += recall\n",
        "        epoch_f1 += f1\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_precision / len(\n",
        "        iterator), epoch_recall / len(iterator), epoch_f1 / len(iterator)"
      ],
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PYNcwKnAz5Hf"
      },
      "source": [
        "#### `Definimos la función de evaluación`\n",
        "\n",
        "Evalua el rendimiento actual de la red usando los datos de validación. \n",
        "\n",
        "Por cada batch de estos datos, calcula y reporta el loss y las métricas asociadas al conjunto de validación. \n",
        "Ya que las métricas son calculadas por cada batch, estas son retornadas promediadas por el número de batches entregados. (ver linea del return)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:54.527162Z",
          "start_time": "2020-06-23T22:25:54.518186Z"
        },
        "colab_type": "code",
        "id": "WsRuiUuHiicY",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_precision = 0\n",
        "    epoch_recall = 0\n",
        "    epoch_f1 = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Indicamos que ahora no guardaremos los gradientes\n",
        "    with torch.no_grad():\n",
        "        # Por cada batch\n",
        "        for batch in iterator:\n",
        "\n",
        "            text = batch.text\n",
        "            tags = batch.nertags\n",
        "\n",
        "            # Predecimos\n",
        "            predictions = model(text)\n",
        "\n",
        "            predictions = predictions.view(-1, predictions.shape[-1])\n",
        "            tags = tags.view(-1)\n",
        "\n",
        "            # Calculamos el Cross Entropy de las predicciones con respecto a las etiquetas reales\n",
        "            loss = criterion(predictions, tags)\n",
        "\n",
        "            # Calculamos las métricas\n",
        "            precision, recall, f1 = calculate_metrics(predictions, tags)\n",
        "\n",
        "            # Actualizamos el loss y las métricas\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_precision += precision\n",
        "            epoch_recall += recall\n",
        "            epoch_f1 += f1\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_precision / len(\n",
        "        iterator), epoch_recall / len(iterator), epoch_f1 / len(iterator)"
      ],
      "execution_count": 237,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:54.535141Z",
          "start_time": "2020-06-23T22:25:54.529158Z"
        },
        "colab_type": "code",
        "id": "Xs-n9Y5yiica",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hy3MVf5H0A94"
      },
      "source": [
        "\n",
        "#### Entrenamiento de la red\n",
        "\n",
        "En este cuadro de código ejecutaremos el entrenamiento de la red.\n",
        "Para esto, primero definiremos el número de épocas y luego por cada época, ejecutaremos `train` y `evaluate`.\n",
        "\n",
        "**Importante: Reiniciar los pesos del modelo**\n",
        "\n",
        "Si ejecutas nuevamente esta celda, se seguira entrenando el mismo modelo una y otra vez. \n",
        "Para reiniciar el modelo se debe ejecutar nuevamente la celda que contiene la función `init_weights`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T21:49:02.524817Z",
          "start_time": "2020-06-23T21:47:09.863026Z"
        },
        "colab_type": "code",
        "id": "iK5lQqpviicf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "outputId": "b2983481-7720-43c6-8a0c-8a1c78138815"
      },
      "source": [
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Recuerdo: train_iterator y valid_iterator contienen el dataset dividido en batches.\n",
        "\n",
        "    # Entrenar\n",
        "    train_loss, train_precision, train_recall, train_f1 = train(\n",
        "        model, train_iterator, optimizer, criterion)\n",
        "\n",
        "    # Evaluar (valid = validación)\n",
        "    valid_loss, valid_precision, valid_recall, valid_f1 = evaluate(\n",
        "        model, valid_iterator, criterion)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    # Si obtuvimos mejores resultados, guardamos este modelo en el almacenamiento (para poder cargarlo luego)\n",
        "    # Si detienen el entrenamiento prematuramente, pueden cargar el modelo en el siguiente recuadro de código.\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), '{}.pt'.format(model_name))\n",
        "    # Si ya no mejoramos el loss de validación, terminamos de entrenar.\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(\n",
        "        f'\\tTrain Loss: {train_loss:.3f} | Train f1: {train_f1:.2f} | Train precision: {train_precision:.2f} | Train recall: {train_recall:.2f}'\n",
        "    )\n",
        "    print(\n",
        "        f'\\t Val. Loss: {valid_loss:.3f} |  Val. f1: {valid_f1:.2f} |  Val. precision: {valid_precision:.2f} | Val. recall: {valid_recall:.2f}'\n",
        "    )"
      ],
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 6s\n",
            "\tTrain Loss: 0.435 | Train f1: 0.24 | Train precision: 0.41 | Train recall: 0.19\n",
            "\t Val. Loss: 0.274 |  Val. f1: 0.45 |  Val. precision: 0.61 | Val. recall: 0.41\n",
            "Epoch: 02 | Epoch Time: 0m 6s\n",
            "\tTrain Loss: 0.142 | Train f1: 0.62 | Train precision: 0.70 | Train recall: 0.58\n",
            "\t Val. Loss: 0.222 |  Val. f1: 0.60 |  Val. precision: 0.72 | Val. recall: 0.56\n",
            "Epoch: 03 | Epoch Time: 0m 6s\n",
            "\tTrain Loss: 0.066 | Train f1: 0.76 | Train precision: 0.79 | Train recall: 0.74\n",
            "\t Val. Loss: 0.195 |  Val. f1: 0.64 |  Val. precision: 0.72 | Val. recall: 0.60\n",
            "Epoch: 04 | Epoch Time: 0m 6s\n",
            "\tTrain Loss: 0.037 | Train f1: 0.82 | Train precision: 0.84 | Train recall: 0.81\n",
            "\t Val. Loss: 0.236 |  Val. f1: 0.64 |  Val. precision: 0.72 | Val. recall: 0.60\n",
            "Epoch: 05 | Epoch Time: 0m 6s\n",
            "\tTrain Loss: 0.024 | Train f1: 0.85 | Train precision: 0.86 | Train recall: 0.84\n",
            "\t Val. Loss: 0.249 |  Val. f1: 0.64 |  Val. precision: 0.72 | Val. recall: 0.62\n",
            "Epoch: 06 | Epoch Time: 0m 6s\n",
            "\tTrain Loss: 0.017 | Train f1: 0.87 | Train precision: 0.88 | Train recall: 0.87\n",
            "\t Val. Loss: 0.261 |  Val. f1: 0.64 |  Val. precision: 0.71 | Val. recall: 0.61\n",
            "Epoch: 07 | Epoch Time: 0m 6s\n",
            "\tTrain Loss: 0.014 | Train f1: 0.88 | Train precision: 0.89 | Train recall: 0.88\n",
            "\t Val. Loss: 0.261 |  Val. f1: 0.65 |  Val. precision: 0.71 | Val. recall: 0.63\n",
            "Epoch: 08 | Epoch Time: 0m 6s\n",
            "\tTrain Loss: 0.011 | Train f1: 0.90 | Train precision: 0.91 | Train recall: 0.90\n",
            "\t Val. Loss: 0.273 |  Val. f1: 0.65 |  Val. precision: 0.72 | Val. recall: 0.63\n",
            "Epoch: 09 | Epoch Time: 0m 6s\n",
            "\tTrain Loss: 0.011 | Train f1: 0.91 | Train precision: 0.92 | Train recall: 0.91\n",
            "\t Val. Loss: 0.268 |  Val. f1: 0.65 |  Val. precision: 0.72 | Val. recall: 0.63\n",
            "Epoch: 10 | Epoch Time: 0m 6s\n",
            "\tTrain Loss: 0.010 | Train f1: 0.91 | Train precision: 0.92 | Train recall: 0.91\n",
            "\t Val. Loss: 0.271 |  Val. f1: 0.66 |  Val. precision: 0.73 | Val. recall: 0.63\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CFoTZ96TFPm",
        "colab_type": "text"
      },
      "source": [
        "**Importante**: Recuerden que el último modelo entrenado no es el mejor (probablemente esté *overfitteado*), si no el que guardamos con la menor loss del conjunto de validación.\n",
        "Para cargar el mejor modelo entrenado, ejecuten la siguiente celda.\n",
        "\n",
        "Este problema lo pueden solucionar con *early stopping*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:58.680706Z",
          "start_time": "2020-06-23T22:25:58.663725Z"
        },
        "colab_type": "code",
        "id": "y27CNYfrjtQ-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ad02a9a8-2cf2-4d09-f163-b55ec60246ef"
      },
      "source": [
        "# cargar el mejor modelo entrenado.\n",
        "model.load_state_dict(torch.load('{}.pt'.format(model_name)))"
      ],
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 240
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T21:52:04.077979Z",
          "start_time": "2020-06-23T21:52:04.072991Z"
        },
        "id": "5CruLTZ2TFPo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Limpiar ram de cuda\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 241,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kBctQHTh0lxD"
      },
      "source": [
        "#### Evaluamos el set de validación con el modelo final\n",
        "\n",
        "Estos son los resultados de predecir el dataset de evaluación con el *mejor* modelo entrenado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:26:01.788742Z",
          "start_time": "2020-06-23T22:26:00.558829Z"
        },
        "colab_type": "code",
        "id": "s0gVbP8yiicj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "11fc6e21-6ba1-4ccf-983d-c06c25dc3074"
      },
      "source": [
        "valid_loss, valid_precision, valid_recall, valid_f1 = evaluate(\n",
        "    model, valid_iterator, criterion)\n",
        "\n",
        "print(\n",
        "    f'Val. Loss: {valid_loss:.3f} |  Val. f1: {valid_f1:.2f} | Val. precision: {valid_precision:.2f} | Val. recall: {valid_recall:.2f}'\n",
        ")"
      ],
      "execution_count": 242,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Val. Loss: 0.195 |  Val. f1: 0.64 | Val. precision: 0.72 | Val. recall: 0.60\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uF1ysw_Kw6zz"
      },
      "source": [
        "\n",
        "### Predecir datos para la competencia\n",
        "\n",
        "Ahora, a partir de los datos de **test** y nuestro modelo entrenado, predeciremos las etiquetas que serán evaluadas en la competencia."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:31:56.776563Z",
          "start_time": "2020-06-23T22:31:39.654525Z"
        },
        "colab_type": "code",
        "id": "1RBs3UU4wLk3",
        "colab": {}
      },
      "source": [
        "def predict_labels(model, iterator, criterion, fields=fields):\n",
        "\n",
        "    # Extraemos los vocabularios.\n",
        "    text_field = fields[0][1]\n",
        "    nertags_field = fields[1][1]\n",
        "    tags_vocab = nertags_field.vocab.itos\n",
        "    words_vocab = text_field.vocab.itos\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for batch in iterator:\n",
        "\n",
        "            text_batch = batch.text\n",
        "            text_batch = torch.transpose(text_batch, 0, 1).tolist()\n",
        "\n",
        "            # Predecir los tags de las sentences del batch\n",
        "            predictions_batch = model(batch.text)\n",
        "            predictions_batch = torch.transpose(predictions_batch, 0, 1)\n",
        "\n",
        "            # por cada oración predicha:\n",
        "            for sentence, sentence_prediction in zip(text_batch,\n",
        "                                                     predictions_batch):\n",
        "                for word_idx, word_predictions in zip(sentence,\n",
        "                                                      sentence_prediction):\n",
        "                    # Obtener el indice del tag con la probabilidad mas alta.\n",
        "                    argmax_index = word_predictions.topk(1)[1]\n",
        "\n",
        "                    current_tag = tags_vocab[argmax_index]\n",
        "                    # Obtenemos la palabra\n",
        "                    current_word = words_vocab[word_idx]\n",
        "\n",
        "                    if current_word != '<pad>':\n",
        "                        predictions.append([current_word, current_tag])\n",
        "\n",
        "\n",
        "    return predictions\n",
        "\n",
        "\n",
        "predictions = predict_labels(model, test_iterator, criterion)"
      ],
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YwQp1Ru8Oht8"
      },
      "source": [
        "### Generar el archivo para la submission\n",
        "\n",
        "No hay problema si aparecen unk en la salida. Estos no son relevantes para evaluarlos, usamos solo los tags."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:33:41.845955Z",
          "start_time": "2020-06-23T22:33:41.731717Z"
        },
        "colab_type": "code",
        "id": "RPfZkjJGkWyq",
        "colab": {}
      },
      "source": [
        "import os, shutil\n",
        "\n",
        "if (os.path.isfile('./predictions.zip')):\n",
        "    os.remove('./predictions.zip')\n",
        "\n",
        "if (not os.path.isdir('./predictions')):\n",
        "    os.mkdir('./predictions')\n",
        "\n",
        "else:\n",
        "    # Eliminar predicciones anteriores:\n",
        "\n",
        "    shutil.rmtree('./predictions')\n",
        "    os.mkdir('./predictions')\n",
        "\n",
        "f = open('predictions/predictions.txt', 'w')\n",
        "for word, tag in predictions:\n",
        "    f.write(word + ' ' + tag + '\\n')\n",
        "f.write('\\n')\n",
        "f.close()\n",
        "\n",
        "a = shutil.make_archive('predictions', 'zip', './predictions')"
      ],
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T21:49:19.575711Z",
          "start_time": "2020-06-23T21:49:19.100486Z"
        },
        "colab_type": "code",
        "id": "k2PqvJAmTFWR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "c4eec046-bf66-44b3-969e-5aac4bd4b420"
      },
      "source": [
        "# A veces no funciona a la primera. Ejecutar mas de una vez para obtener el archivo...\n",
        "from google.colab import files\n",
        "files.download('predictions.zip')  "
      ],
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_b0f6381b-5aac-42a1-8b44-eaef7668b91d\", \"predictions.zip\", 110100)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ta1hTsixFE28",
        "colab_type": "text"
      },
      "source": [
        "##Experimentos y Resultados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXJOXwwAFKv4",
        "colab_type": "text"
      },
      "source": [
        "Modelo RNN LSTM sin embedding preentrenados\n",
        "\n",
        "\n",
        "|       | batches | emb_dim | hidden_dim | n_layers | dropout | bidirectional | epochs | Val Recall | Val Precision | Val F1 | Val Loss |\n",
        "|-------|---------|---------|------------|----------|---------|---------------|--------|------------|---------------|--------|----------|\n",
        "| Exp1  | 128     | 300     | 128        | 5        | 0,1     | VERDADERO     | 20     | 0,45       | 0,69          | 0,53   | 0,295    |\n",
        "| Exp2  | 64      | 100     | 128        | 3        | 0,25    | FALSO         | 20     | 0,56       | 0,62          | 0,57   | 0,287    |\n",
        "| Exp3  | 64      | 100     | 128        | 3        | 0,25    | VERDADERO     | 10     | 0,62       | 0,68          | 0,63   | 0,209    |\n",
        "| Exp4  | 64      | 100     | 256        | 3        | 0,25    | VERDADERO     | 10     | 0,61       | 0,66          | 0,61   | 0,206    |\n",
        "| Exp5  | 64      | 100     | 256        | 5        | 0,25    | VERDADERO     | 10     | 0,62       | 0,69          | 0,64   | 0,265    |\n",
        "| Exp6  | 128     | 100     | 128        | 6        | 0,25    | VERDADERO     | 20     | 0,58       | 0,64          | 0,6    | 0,252    |\n",
        "| Exp7  | 128     | 100     | 256        | 5        | 0,1     | VERDADERO     | 20     | 0,53       | 0,61          | 0,56   | 0,251    |\n",
        "| Exp8  | 128     | 300     | 256        | 5        | 0,25    | VERDADERO     | 20     | 0,56       | 0,66          | 0,6    | 0,244    |\n",
        "| Exp9  | 128     | 300     | 256        | 5        | 0,25    | VERDADERO     | 10     | 0,58       | 0,65          | 0,6    | 0,242    |\n",
        "| Exp10 | 64      | 100     | 256        | 5        | 0,25    | VERDADERO     | 10     | 0,59       | 0,65          | 0,6    | 0,198    |\n",
        "\n",
        "\n",
        "Mejores Resultados:\n",
        "\n",
        "|      | batches | emb_dim | hidden_dim | n_layers | dropout | bidirectional | epochs | Val Recall | Val Precision | Val F1 | Val Loss |\n",
        "|------|---------|---------|------------|----------|---------|---------------|--------|------------|---------------|--------|----------|\n",
        "| Exp5 | 64      | 100     | 256        | 5        | 0,25    | VERDADERO     | 10     | 0,62       | 0,69          | 0,64   | 0,265    |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LucDAc3F3yM",
        "colab_type": "text"
      },
      "source": [
        "Modelo RNN GRU sin embedding preentrenado\n",
        "\n",
        "\n",
        "|       | batches | emb_dim | hidden_dim | n_layers | dropout | bidirectional | epochs | Val Recall | Val Precision | Val F1 | Val Loss |\n",
        "|-------|---------|---------|------------|----------|---------|---------------|--------|------------|---------------|--------|----------|\n",
        "| Exp1  | 64      | 300     | 128        | 2        | 0,25    | VERDADERO     | 10     | 0,61       | 0,72          | 0,64   | 0,19     |\n",
        "| Exp2  | 64      | 300     | 128        | 3        | 0,25    | VERDADERO     | 10     | 0,55       | 0,71          | 0,6    | 0,208    |\n",
        "| Exp3  | 64      | 300     | 128        | 4        | 0,25    | VERDADERO     | 10     | 0,59       | 0,69          | 0,62   | 0,198    |\n",
        "| Exp4  | 64      | 300     | 256        | 4        | 0,25    | VERDADERO     | 10     | 0,55       | 0,7           | 0,58   | 0,209    |\n",
        "| Exp5  | 64      | 300     | 256        | 2        | 0,25    | VERDADERO     | 10     | 0,62       | 0,73          | 0,65   | 0,191    |\n",
        "| Exp6  | 64      | 300     | 512        | 2        | 0,25    | VERDADERO     | 10     | 0,58       | 0,72          | 0,62   | 0,197    |\n",
        "| Exp7  | 64      | 300     | 256        | 3        | 0,25    | VERDADERO     | 10     | 0,63       | 0,74          | 0,66   | 0,182    |\n",
        "| Exp8  | 64      | 300     | 256        | 3        | 0,1     | VERDADERO     | 10     | 0,62       | 0,73          | 0,66   | 0,189    |\n",
        "| Exp9  | 64      | 300     | 256        | 4        | 0,25    | VERDADERO     | 10     | 0,63       | 0,7           | 0,64   | 0,195    |\n",
        "| Exp10 | 64      | 300     | 128        | 3        | 0,25    | VERDADERO     | 10     | 0,6        | 0,72          | 0,64   | 0,195    |\n",
        "\n",
        "Mejores Resultados\n",
        "\n",
        "|      | batches | emb_dim | hidden_dim | n_layers | dropout | bidirectional | epochs | Val Recall | Val Precision | Val F1 | Val Loss |\n",
        "|------|---------|---------|------------|----------|---------|---------------|--------|------------|---------------|--------|----------|\n",
        "| Exp7 | 64      | 300     | 256        | 3        | 0,25    | VERDADERO     | 10     | 0,63       | 0,74          | 0,66   | 0,182    |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3zqfTJYKsBF",
        "colab_type": "text"
      },
      "source": [
        "Modelo RNN LSTM con embeddings preentrenados\n",
        "\n",
        "|      | batches | emb_dim | hidden_dim |  | n_layers | dropout | bidirectional | epochs | freeze    | Embedding | Val Recall | Val Precission | Val F1 | Val Loss |\n",
        "|------|---------|---------|------------|--|----------|---------|---------------|--------|-----------|-----------|------------|----------------|--------|----------|\n",
        "| Exp1 | 30      | 300     | 128        |  | 4        | 0,25    | VERDADERO     | 10     | VERDADERO | Glove     | 0,56       | 0,68           | 0,59   | 0,241    |\n",
        "| Exp2 | 100     | 300     | 256        |  | 5        | 0,5     | VERDADERO     | 10     | VERDADERO | Glove     | 0,45       | 0,66           | 0,52   | 0,297    |\n",
        "| Exp3 | 100     | 300     | 128        |  | 5        | 0,15    | VERDADERO     | 10     | VERDADERO | Glove     | 0,54       | 0,66           | 0,58   | 0,268    |\n",
        "| Exp4 | 100     | 300     | 64         |  | 4        | 0,25    | VERDADERO     | 20     | VERDADERO | Glove     | 0,53       | 0,66           | 0,57   | 0,253    |\n",
        "| Exp5 | 30      | 300     | 128        |  | 7        | 0,25    | VERDADERO     | 20     | VERDADERO | Glove     | 0,56       | 0,69           | 0,59   | 0,245    |\n",
        "| Exp6 | 30      | 300     | 128        |  | 4        | 0,25    | VERDADERO     | 20     | VERDADERO | FastText  | 0,54       | 0,66           | 0,57   | 0,247    |\n",
        "| Exp7 | 30      | 300     | 256        |  | 5        | 0,5     | VERDADERO     | 10     | VERDADERO | FastText  | 0,53       | 0,66           | 0,56   | 0,262    |\n",
        "| Exp8 | 30      | 300     | 128        |  | 5        | 0,15    | VERDADERO     | 10     | VERDADERO | FastText  | 0,55       | 0,67           | 0,57   | 0,241    |\n",
        "\n",
        "Mejores Resultados\n",
        "\n",
        "|      | batches | emb_dim | hidden_dim |  | n_layers | dropout | bidirectional | epochs | freeze    | Embedding | Val Recall | Val Precission | Val F1 | Val Loss |\n",
        "|------|---------|---------|------------|--|----------|---------|---------------|--------|-----------|-----------|------------|----------------|--------|----------|\n",
        "| Exp5 | 30      | 300     | 128        |  | 7        | 0,25    | VERDADERO     | 20     | VERDADERO | Glove     | 0,56       | 0,69           | 0,59   | 0,245    |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQRU7YLgKsNu",
        "colab_type": "text"
      },
      "source": [
        "Modelo RNN GRU con embedding preentrenados\n",
        "\n",
        "|      | batches | emb_dim | hidden_dim |   | n_layers | dropout | bidirectional | epochs | freeze    | Embedding | Val Recall | Val Precission | Val F1 | Val Loss |\n",
        "|------|---------|---------|------------|---|----------|---------|---------------|--------|-----------|-----------|------------|----------------|--------|----------|\n",
        "| Exp1 | 30      | 300     | 128        |   | 4        | 0,25    | VERDADERO     | 20     | VERDADERO | Glove     | 0,5        | 0,68           | 0,54   | 0,274    |\n",
        "| Exp2 | 64      | 300     | 256        | 3 | 3        | 0,25    | VERDADERO     | 10     | VERDADERO | Glove     | 0,47       | 0,67           | 0,53   | 0,306    |\n",
        "| Exp3 | 64      | 300     | 128        |   | 2        | 0,25    | VERDADERO     | 10     | VERDADERO | Glove     | 0,48       | 0,68           | 0,52   | 0,304    |\n",
        "| Exp4 | 30      | 300     | 128        |   | 4        | 0,25    | VERDADERO     | 20     | VERDADERO | FastText  | 0,5        | 0,66           | 0,54   | 0,276    |\n",
        "| Exp5 | 64      | 300     | 256        | 3 | 3        | 0,25    | VERDADERO     | 20     | VERDADERO | FastText  | 0,5        | 0,69           | 0,56   | 0,304    |\n",
        "| Exp6 | 64      | 300     | 128        |   | 2        | 0,25    | VERDADERO     | 10     | VERDADERO | FastText  | 0,5        | 0,71           | 0,56   | 0,29     |\n",
        "| Exp7 | 64      | 300     | 256        |   | 3        | 0,1     | VERDADERO     | 10     | FALSO     | FastText  | 0,57       | 0,7            | 0,61   | 0,219    |\n",
        "| Exp8 | 64      | 300     | 256        |   | 3        | 0,3     | VERDADERO     | 20     | VERDADERO | FastText  | 0,51       | 0,69           | 0,56   | 0,295    |\n",
        "\n",
        "Mejores Resultados\n",
        "\n",
        "\n",
        "|      | batches | emb_dim | hidden_dim |  | n_layers | dropout | bidirectional | epochs | freeze | Embedding | Val Recall | Val Precission | Val F1 | Val Loss |\n",
        "|------|---------|---------|------------|--|----------|---------|---------------|--------|--------|-----------|------------|----------------|--------|----------|\n",
        "| Exp9 | 64      | 300     | 256        |  | 3        | 0,1     | VERDADERO     | 10     | FALSO  | FastText  | 0,57       | 0,7            | 0,61   | 0,219    |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LmVxYWJM4K5",
        "colab_type": "text"
      },
      "source": [
        "Resumen Mejores Resultados\n",
        "\n",
        "| Model         | Exp# | batches | emb_dim | hidden_dim | n_layers | dropout | bidirectional | epochs | freeze    | Embedding | Val Recall | Val Precission | Val F1 | Val Loss |\n",
        "|---------------|------|---------|---------|------------|----------|---------|---------------|--------|-----------|-----------|------------|----------------|--------|----------|\n",
        "| LSTM emb pree | Exp5 | 30      | 300     | 128        | 7        | 0,25    | VERDADERO     | 20     | VERDADERO | Glove     | 0,56       | 0,69           | 0,59   | 0,245    |\n",
        "| GRU emb pree  | Exp5 | 64      | 300     | 256        | 3        | 0,1     | VERDADERO     | 10     | FALSO     | FastText  | 0,57       | 0,7            | 0,61   | 0,219    |\n",
        "| LSTM          | Exp5 | 64      | 100     | 256        | 5        | 0,25    | VERDADERO     | 10     | -         | -         | 0,62       | 0,69           | 0,64   | 0,265    |\n",
        "| GRU           | Exp7 | 64      | 300     | 256        | 3        | 0,25    | VERDADERO     | 10     | -         | -         | 0,63       | 0,74           | 0,66   | 0,182    |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LZEWJXrNaSIf"
      },
      "source": [
        "## Conclusiones\n",
        "\n",
        "\n",
        "Como se puede observar en la tabla de resumen de la sección de mejores resultados, los mejores resultados obtenidos fueron para el modelo RNN tipo GRU sin embeddings preentrenados, seguido de cerca por el modelo RNN tipo LSTM sin embeddings preentrenados. Estos modelos se alejan en primera instancia de los resultados obtenidos con sus símiles con embeddings preenrtenados. \n",
        "\n",
        "Esta diferencia entre arquitecturas es un resultado inesperado para el equipo de desarrollo, en tanto que el uso de embeddings preentrenados tenía la intención de mejorar los resultados obtenidos sin ellos. Las posibles explicaciones son las eventuales diferencias entre el dataset sobre el que se entrenó en este informe versus la fuente sobre la que se entrenaron los embeddings preentrenados utilizados. Y también que la forma en que se inicializaron pudo no ser la óptima para aprovechar sus características.\n",
        "\n",
        "Con respecto a las métricas de evaluación, notamos que los resultados obtenidos tienden a sobresalir en Precision pero a bajar en Recall. La explicación tiene que ver, primero, con el trade-off entre estas dos métricas de evaluación; y segundo en que los resultados mostraron mayor capacidad de acertar una etiqueta correctamente.\n",
        "Por esta razón, el F1-Score tendía a mantenerse al avanzar los experimentos, debido a que mejorar aún más el Precision perjudicaba el Recall y viceversa.\n",
        "\n",
        "En lo que concierne a los hiperparámetros que se variaron para esta tarea, la primera conclusión es que la bidireccionalidad ayudó a mejorar los resultados (fue una de las primeras variables que fueron claras en los experimentos preliminares durante la construcción de las arquitecturas), debido a que se hace cargo del contexto en que aparecen las palabras. Luego, que para las arquitecturas sin embeddings preentrenados con 10 épocas bastaba para obtener buenos resultados sin overfitting, mientras que con embeddings preentrenados a veces se nececsitaba llegar a 20 para mejorar los resultados. Un dropout de 0,25 ayudó a mantener estables los resultados, ya que cuando se varió no se obtuvieron mejores resultados controlando el overfitting, que es la misión del dropout. En general aumentar la cantidad de layers de la RNN fue productivo, pero hasta cierto punto, por lo general mejoraba los resultados en las primeras interaciones, como también lo hacía aumentar las dimensiones ocultas. Finalmente, para embeddings no preentrenados, aumentar el tamaño a más de 300 no mostró mejorar los resultados, pero sí mejoró con respecto a 100.\n",
        "\n",
        "Antes de proponer trabajo futuro cabe mencionar que el optimizer no se varió, pues la investigación previa mostró que Adam tendía a ser la elección para este tipo de problema y muchos otros en NLP. Por eso se decidió usar Adam a lo largo de todos los experimentos, pero sin lugar a dudas sería provechoso porbar otros optimizadores, y por eso se deja propuesto para futuros trabajos.\n",
        "También se propone variar la función de Loss, ya que en este trabajo solamente se utilizó una CrossEntropyLoss dado que experimentos preliminares durante la creación de arquitectura mostraron resultados menos que aceptables con otras funciones que se probaron. Se propone investigar las funciones de Loss más usadas para NER para poder ser usadas como un parámetro a variar en este trabajo. También se propone probar diferentes embeddings preentrenados en españos, haciendo uso de BERT y Flair, para probar mejorar las performance de los usados en este informe, e investigar diferentes maneras de incorporarlos al modelo.\n",
        "\n",
        "Finalmente, concluimos que se cumplieron los objetivos, pues se mejoraron los resultados inciales del baseline entregado por el equipo docente en las tres métricas a evaluar, se utilizaron diferentes herramientas para poder optmizar los resultados y se propusieron mejoras y experimentos para trabajos futuros en esta misma tarea.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sm2dprpWbB-H",
        "colab_type": "text"
      },
      "source": [
        "## Anexos\n",
        "\n",
        "1. Tabla completa de resultados obtenidos por cada experimento con tablas de resumen general y para cada experimento: \n",
        "\n",
        "https://docs.google.com/spreadsheets/d/1rF5ApuZYQ_dXKC8vitxjzhDIylq_DvVRpCIgfbMA9WM/edit?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1S4N4858XhHX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}